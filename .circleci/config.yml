aliases:
  - &filter-only-prs-dependabot
    branches:
      only:
        - /^pull\/.+$/
        - /^dependabot\/.+$/
  - &filter-only-auto-canary
    branches:
      only:
        - auto
        - canary
  - &working_directory /opt/git/diem
  - &image libra/build_environment:circleci-2

version: 2.1

orbs:
  slack: circleci/slack@3.3.0
  aws-ecr: circleci/aws-ecr@6.12.2
  aws-cli: circleci/aws-cli@0.1.13

executors:
  docker-xlarge-executor:
    docker:
      - image: *image
    resource_class: xlarge
  docker-medium-executor:
    docker:
      - image: *image
    resource_class: medium
  vm-xlarge-caching-executor:
    machine:
      docker_layer_caching: true
      image: ubuntu-1604:202004-01
    resource_class: xlarge
  vm-xlarge-executor:
    machine:
      docker_layer_caching: false
      image: ubuntu-1604:202004-01
    resource_class: xlarge
  vm-large-executor:
    machine:
      docker_layer_caching: false
      image: ubuntu-1604:202004-01
    resource_class: large
  vm-medium-executor:
    machine:
      docker_layer_caching: false
      image: ubuntu-1604:202004-01
    resource_class: medium

commands:
  install_deps_on_vm_executor:
    description: Install build dependencies on vm executor
    steps:
      - run:
          name: Update Debian package source
          command: |
            sudo apt-get update
      - run:
          name: Install Dependencies
          command: |
            sudo apt-get install -y cmake curl clang llvm
      - run:
          name: Install rustup and cargo if not found in container
          command: |
            if ! [ -x "$(command -v cargo)" ] || ! [ -x "$(command -v rustup)" ]; then \
              curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs \
              | sh -s -- -y --default-toolchain $(cat rust-toolchain); \
              echo 'export PATH=$PATH:~/.cargo/bin' >> $BASH_ENV; \
            fi
      - run:
          name: Install nightly version of rust toolchain for cargo with v2 feature resolver
          command: rustup install $(cat cargo-toolchain)
      - run:
          name: Install specific version of rust toolchain
          command: rustup install $(cat rust-toolchain)
      - run:
          name: Version Information
          command: rustc --version; cargo --version; rustup --version
      - run:
          name: Install Rust linters
          command: |
            rustup component add clippy rustfmt --toolchain $(cat rust-toolchain)
  print_versions:
    description: Version Info
    steps:
      - run:
          name: Version Info
          command: rustup --version ; rustc --version
  shell_setup:
    description: Shell Setup
    steps:
      - run:
          name: Setup Env
          command: |
            mkdir -p /opt/cargo/
            export CARGO_HOME=/opt/cargo/
            echo 'export CARGO_HOME=/opt/cargo/' >> $BASH_ENV
            echo 'export TAG=0.1.${CIRCLE_BUILD_NUM}' >> $BASH_ENV
            echo 'export IMAGE_NAME=myapp' >> $BASH_ENV
            echo 'export LIBRA_DUMP_LOGS=1' >> $BASH_ENV
            echo 'export CARGO_INCREMENTAL=0' >> $BASH_ENV
            echo 'export CI_TIMEOUT="timeout 70m"' >> $BASH_ENV
            export RUST_NIGHTLY=$(cat cargo-toolchain)
            echo 'export RUST_NIGHTLY='"$RUST_NIGHTLY" >> $BASH_ENV

            # Turn on the experimental feature resolver in cargo. See:
            # https://doc.rust-lang.org/nightly/cargo/reference/unstable.html#features
            echo 'export CARGOFLAGS='$(cat cargo-flags) >> $BASH_ENV
            # Use nightly version of cargo to access the new feature resolver
            echo 'export CARGO='$(rustup which cargo --toolchain "$RUST_NIGHTLY") >> $BASH_ENV
            # Pin the version of RUSTC used for all invocations of cargo
            echo 'export RUSTUP_TOOLCHAIN="$(cat rust-toolchain)"' >> $BASH_ENV
  move_shell_setup:
    description: Shell Setup
    steps:
      - run:
          name: Setup Env
          command: |
            # Configure Move prover tools
            echo 'export Z3_EXE="$HOME/bin/z3"' >> $BASH_ENV
            echo 'export DOTNET_ROOT="$HOME/.dotnet"' >> $BASH_ENV
            echo 'export BOOGIE_EXE="$HOME/.dotnet/tools/boogie"' >> $BASH_ENV
  fail_if_debian_buster_docker_base_images_are_not_tagged_with_sha256:
    steps:
      - run:
          name: Verify all debian buster images have sha256s.
          when: always
          command: |
            set -e
            # We are using debian for our base images.   Get all debain tags in FROM lines, strip the "AS .*" part
            ALL_BUSTER_TAGS=$(grep --include=\*Dockerfile -r '.' -e 'FROM debian:' | sed 's/[ ]*[a|A][s|S] .*$//g')
            while IFS= read -r line ; do
              # if the line does not end in a git tag, echo the line and mark the build as bad.
              if [[ ! $line =~ '@sha256:' ]]; then
                echo "Give this docker image FROM line a sha256 in it's tag.   Failing the build."
                echo "$line";
                SHOULD_FAIL="true";
              else
                echo checked "$line"
              fi
            done \<<< "$ALL_BUSTER_TAGS"
            if [[ "$SHOULD_FAIL" == "true" ]]; then
              exit 1
            fi
  halt_if_no_relevant_files_changed_since_last_evaluation:
    description: |
      halts the job if no relevant files have changed.
      This is determined by using a cached file containing the last git revision the build evaluated.
      Branch is part of the cache key name, following the parameter, cache_key_part.
      The build did not necessarily need to proceed on the last evaluation if no relevant files had changed,
      and cache keys will still be updated on each evaluation before halting.
      If this build is the result of a pull request, bors auto run, the pr information is prefered over the $previoushead,
      and compared to the merge base of the target branch.
      Relevant files are looked up from an existing file on the execution env, passed in as a parameter, the
      file of relevant git files.
    parameters:
      cache_key_part:
        description: part of the cache key name used by circle in the job.
        type: string
      file_of_relevant_git_files:
        description: file to be provided to these steps, of relevant git files.
        type: string
    steps:
      - restore_cache:
          name: restore latch cache file.
          key: last-githash-{{ .Environment.CIRCLE_BRANCH }}-<< parameters.cache_key_part >>
      - run:
          name: Detect if relevant files have changed.
          command: |
            touch /home/circleci/lastbuildgithash
            previoushead=$(cat /home/circleci/lastbuildgithash)
            output=$(.circleci/get_pr_info.sh -g $previoushead -b)
            echo Output: "$output"
            eval "$output"
            echo Changed: $(cat "$CHANGED_FILE_OUTPUTFILE")
            if [[ -n "$BASE_GITHASH" ]] && [ $(join "$CHANGED_FILE_OUTPUTFILE" << parameters.file_of_relevant_git_files >> | wc -l) == 0 ]; then
              echo no relevant files have changed will halt
              echo "halt" > /tmp/should_halt
            else
              echo Relevant files have changed - or could not detect changes, building.
              echo "continue" > /tmp/should_halt
            fi
            git rev-parse HEAD > /home/circleci/lastbuildgithash
      - save_cache:
          name: store updated cache file.
          key: last-githash-{{ .Environment.CIRCLE_BRANCH }}-<< parameters.cache_key_part >>-{{ epoch }}
          paths:
            - /home/circleci/lastbuildgithash
      - run:
          name: halt if no changes
          command: |
            if [[ "$(cat /tmp/should_halt)" == "halt" ]]; then
              echo halting job.
              circleci step halt
            fi

  save_cargo_package_cache:
    description: Save cargo package cache for subsequent jobs
    steps:
      - save_cache:
          name: Save cargo package cache
          key: cargo-package-sccache-new-{{ checksum "Cargo.lock" }}
          # paths are relative to /home/circleci/project/
          paths:
            - "/opt/cargo/git"
            - "/opt/cargo/registry"
            - "/opt/cargo/.package-cache"
  restore_cargo_package_cache:
    description: Restore Cargo package cache from prev job
    steps:
      - run:
          name: Deal with non-relative cache locations.
          command: |
            sudo mkdir -p /usr/local/cargo/
            sudo chmod 777 /usr/local/cargo/
      - restore_cache:
          name: Restore cargo package cache
          key: cargo-package-sccache-new-{{ checksum "Cargo.lock" }}
      - run:
          name: Check cargo package cache
          command: |
            ls -all /opt/cargo
            du -ssh /opt/cargo
  save_breaking_change_rev:
    description: Save the breaking change rev since last testnet update.
    steps:
      - save_cache:
          name: Save breaking change rev
          key: testnet-v1-{{ checksum "testnet_rev" }}
          # paths are relative to /home/circleci/project/
          paths:
            - breaking_change_rev
          when: on_fail
  restore_breaking_change_rev:
    description: Restore the breaking change rev since last testnet update
    steps:
      - restore_cache:
          name: Restore breaking change rev
          key: testnet-v1-{{ checksum "testnet_rev" }}
  send_message:
    description: Send message to the specified webhook, if no webhook is set simply return.
    parameters:
      payload_file:
        description: File containing the message payload
        type: string
        default: ""
      build_url:
        description: This build's URL in Circle
        type: string
        default: "${CIRCLE_BUILD_URL}"
      webhook:
        description: Webhook for the message
        type: string
        default: ""
    steps:
      - run:
          name: Send job status
          command: |
            if [ -e <<parameters.payload_file>> ]; then
              jq -n \
                --arg msg "$(cat <<parameters.payload_file>>)" \
                --arg url "<<parameters.build_url>>" \
                '{
                  attachments: [
                    {
                      text: $msg,
                      actions: [
                        {
                          "type": "button",
                          "text": "Visit Job",
                          "url": $url
                        }
                      ],
                    }
                  ]
                }' > /tmp/payload
              cat /tmp/payload
              if [ <<parameters.webhook>> ]; then
                curl -X POST -H 'Content-type: application/json' -d @/tmp/payload \
                <<parameters.webhook>>
              else
                echo "Not sending messages as no webhook url is set."
                echo "Chances are you are not building on master, or circle is misconfigured."
                echo "webhook is empty"
                exit 0
              fi
            fi
          when: always
  build_setup:
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - print_versions
      - run:
          name: update tooling if needed.
          command: scripts/dev_setup.sh -t -o -b -p -y
      - shell_setup
      - move_shell_setup
  vm_build_setup:
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - install_deps_on_vm_executor
      - run:
          name: install move tools, modify shell
          command: |
            scripts/dev_setup.sh -b -p -y
            source "${HOME}"/.profile
          working_directory: *working_directory
      - shell_setup
      - move_shell_setup
      - print_versions
  build_teardown:
    steps:
      - run:
          name: Check for changed and untracked files
          command: ./scripts/changed-files.sh
  setup_docker_signing:
    steps:
      - run:
          name: Setup docker login and signing if creds are available.
          command: |
            set -x
            if [[ -z "$DOCKERHUB_PASSWORD" ]]; then
              echo Lacking credentials for docker hub, not signing in.
            else
              # echo 'export DOCKER_CONTENT_TRUST=1' >> $BASH_ENV
              echo "$DOCKERHUB_PASSWORD" | docker login -u "$DOCKERHUB_USERNAME" --password-stdin
              export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=${DOCKERHUB_KEY_PASSWORD}
              echo 'export DOCKER_CONTENT_TRUST_REPOSITORY_PASSPHRASE=${DOCKERHUB_KEY_PASSWORD}' >> $BASH_ENV
              mkdir -p ~/.docker/trust/private/
              echo ${DOCKERHUB_KEY_MATERIAL} | base64 -d > ~/.docker/trust/private/${DOCKERHUB_KEY_NAME}.key
              chmod 600 ~/.docker/trust/private/${DOCKERHUB_KEY_NAME}.key
              docker trust key load ~/.docker/trust/private/${DOCKERHUB_KEY_NAME}.key --name "$DOCKERHUB_USERNAME"
              echo Docker hub is logged in, and signing is available.
            fi
  setup_aws:
    description: Set up access to AWS
    steps:
      - run:
          name: Compose AWS Env Variables
          command: |
            echo 'export AWS_ECR_ACCOUNT_URL="${AWS_ECR_ACCOUNT_NUM}.dkr.ecr.${AWS_REGION}.amazonaws.com"' >> $BASH_ENV
      - aws-cli/configure:
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          aws-region: AWS_REGION
      - aws-ecr/ecr-login
jobs:
  prefetch-crates:
    working_directory: *working_directory
    executor: docker-medium-executor
    description: Prefetch cargo crates for subsequent jobs.
    steps:
      - build_setup
      - run:
          name: Git Hooks and Checks
          command: ./scripts/git-checks.sh
      - restore_cargo_package_cache
      - run:
          name: Fetch workspace dependencies over network
          command: |
            echo $CARGO $CARGOFLAGS fetch
            RUST_BACKTRACE=1 $CARGO $CARGOFLAGS fetch
      - save_cargo_package_cache
  check-breaking-change:
    working_directory: *working_directory
    executor: docker-medium-executor
    description: Detect breaking change in CLI
    environment:
      # NOTE The  built-in save_cache and restore_cache cmds dont accept cache
      # path or cache key defined via env var on the fly. As a result, if you
      # change BREAKING_CHANGE_REV_FILE or TESTNET_REV_FILE, make sure to change
      # save_breaking_change_rev and restore_breaking_change_rev accordingly.
      BREAKING_CHANGE_REV_FILE: "breaking_change_rev"
      TESTNET_REV_FILE: "testnet_rev"
    steps:
      - build_setup
      - run:
          name: Prepare cache key for breaking change rev lookup
          # NOTE save_cache and restore_cache dont take cache key defined via
          # env var on the fly. So we are going to store the testnet rev in a
          # file and use its checksum as cache key.
          command: |
            echo 'export GIT_REV=$(git rev-parse HEAD)' >> $BASH_ENV
            git rev-parse origin/testnet > ${TESTNET_REV_FILE}
      - restore_breaking_change_rev
      - run:
          name: Check exiting breaking change rev
          command: |
            pwd
            if [ -f "${BREAKING_CHANGE_REV_FILE}" ]; then
              echo "master already has breaking change $(cat ${BREAKING_CHANGE_REV_FILE})"
              echo "Nothing to do. Halting CI..."
              circleci step halt
            else
              echo "No existing breacking change rev. Will continue CI."
            fi
      - restore_cargo_package_cache
      - run:
          name: Construct CLI cmds
          command: |
            echo "
              a c
              a m 0 10 LBR false
              q b 0
              a c
              a m 1 11 LBR false
              q b 1
              t 0 1 1 LBR
              q b 0
              q b 1
              quit
            " > /tmp/cli
      - run:
          name: Connect to testnet
          # NOTE +e to disable exit immediately on failure
          command: |
            set +e
            ./scripts/cli/start_cli_testnet.sh < /tmp/cli
            status=$?
            if [[ $status != 0 ]] ; then
              git rev-parse HEAD > ${BREAKING_CHANGE_REV_FILE}
              echo "Will save breaking change rev $(cat ${BREAKING_CHANGE_REV_FILE})"
            fi
            exit $status
      - save_breaking_change_rev
      - slack/status:
          fail_only: true
          webhook: "${WEBHOOK_BREAKING_CHANGE}"
          failure_message: ":red_circle: <@channel> breaking change in *${GIT_REV}*"

  ######################################################################################################
  # Publish docker artifacts for prs targeting release branches built in "auto" by bors.               #
  # Disabled for now, until bors pipeline more configurable.                                           #
  ######################################################################################################
  docker-pre-publish:
    working_directory: *working_directory
    executor: vm-xlarge-caching-executor
    description: publish docker images with a pre-* tag.
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - run:
          name: should pre build docker images (targeting a release branch)?
          command: |
            eval `.circleci/get_pr_info.sh -b`
            if  [[ ! "$TARGET_BRANCH" =~ "^release-[0-9|.]+$" ]] && [[ ! "$TARGET_BRANCH" =~ "^test-[0-9|.]+$" ]] ; then
              echo Targeting branch $TARGET_BRANCH will not publish docker images.
              circleci step halt
            fi
      - setup_docker_signing
      - run:
          name: pre-release docker images
          command: |
            BRANCH=${CIRCLE_BRANCH}
            success=0
            docker/build_push.sh -u -p -b ${BRANCH} -n client || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n init || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n faucet || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n tools || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n validator || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n validator-tcb || success=-1
            docker/build_push.sh -u -p -b ${BRANCH} -n cluster-test || success=-1
            exit $success

  ######################################################################################################
  # Docker Builds:                                                                                     #
  ######################################################################################################
  docker-publish:
    working_directory: *working_directory
    executor: vm-xlarge-caching-executor
    description: publish docker images
    steps:
      - run:
          command: |
            sudo mkdir -p /opt/cargo/
            sudo chown circleci /opt/cargo/
            sudo mkdir -p /opt/git/
            sudo chown circleci /opt/git/
          working_directory: ~/project
      - checkout:
          path: *working_directory
      - setup_docker_signing
      - setup_aws
      - run:
          name: pull pre images (or build if not pullable) and push release docker images
          command: |
            set -x
            BRANCH=${CIRCLE_BRANCH}
            success=0
            docker/build_push.sh -u -b ${BRANCH} -n client || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n init || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n faucet || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n tools || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n validator || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n validator-tcb || success=-1
            docker/build_push.sh -u -b ${BRANCH} -n cluster-test || success=-1
            exit $success
      - run:
          name: docker image pruning.
          command: |
            scripts/dockerhub_prune.sh -u "${DOCKERHUB_USERNAME}" -p "${DOCKERHUB_PASSWORD}" -x
      - run:
          name: push to novi ecr
          when: always
          command: |
            #push to novi ecr with standard names
            BRANCH=${CIRCLE_BRANCH}
            GIT_REV=$(git rev-parse --short=8 HEAD)
            aws ecr get-login-password --region ${AWS_REGION} | \
            docker login --username AWS --password-stdin "${AWS_ECR_ACCOUNT_URL}"
            docker/dockerhub_to_novi_ecr.sh -t ${BRANCH}_${GIT_REV} -r ${AWS_ECR_ACCOUNT_URL}

  ######################################################################################################################
  #  Code Coverage for unit tests (targets S3 html upload, codecov.io output, and slack with failed tests/compilations)
  ######################################################################################################################

  code_coverage:
    working_directory: *working_directory
    executor: vm-xlarge-executor
    description: Run code coverage
    environment:
      MESSAGE_PAYLOAD_FILE: "/tmp/message_payload"
    steps:
      - vm_build_setup
      - run:
          name: install lcov (let x install grcov)
          command: |
            if which lcov &>/dev/null; then
               echo "lcov is already installed"
            else
              sudo apt-get install lcov --no-install-recommends -y
            fi
      - restore_cache:
          name: restore daily latch cache file.
          key: code-coverage-daily
      - run:
          name: Halt job if already built code coverage today.
          command: |
            NOW=`date +%Y-%m-%d`
            LAST=`cat /home/circleci/lastbuild` || true
            if [[ "$LAST" == "$NOW" ]]; then
              echo Last build occured today, halting.
              circleci step halt
            else
              echo Last build occured $LAST, building.
              date +%Y-%m-%d > /home/circleci/lastbuild
            fi
      - save_cache:
          name: store updated daily latch file.
          key: code-coverage-daily-{{ epoch }}
          paths:
            - /home/circleci/lastbuild
      - aws-cli/configure:
          aws-access-key-id: AWS_ACCESS_KEY_ID
          aws-secret-access-key: AWS_SECRET_ACCESS_KEY
          aws-region: AWS_REGION
      - run:
          name: Setup code coverage output
          command: |
            echo "export CODECOV_OUTPUT=codecov" >> $BASH_ENV
      - run:
          name: Run code coverage
          command: |
            cargo xtest --html-cov-dir=$CODECOV_OUTPUT/grcovhtml/ --html-lcov-dir=$CODECOV_OUTPUT/lcovhtml/ --no-fail-fast -j 8 || true
          no_output_timeout: 20m
      - run:
          name: Upload result to codecov.io
          command: bash <(curl -s https://codecov.io/bash) -f $CODECOV_OUTPUT/lcovhtml/lcov.info -F unittest;
      - run:
          name: Push Coverage Reports to S3
          command: |
            set -x
            SUFFIX="$(date +"%Y-%m-%d")-$(git rev-parse --short=8 HEAD)"
            PREFIX="ci-artifacts.diem.com/coverage";
            #Push grcov
            aws s3 cp --recursive ${CODECOV_OUTPUT}/grcovhtml "s3://${PREFIX}/unit-coverage/${SUFFIX}/";
            aws s3 cp --recursive ${CODECOV_OUTPUT}/grcovhtml "s3://${PREFIX}/unit-coverage/latest/";
            echo "Grcov available in s3 https://${PREFIX}/unit-coverage/${SUFFIX}/index.html" >> ${MESSAGE_PAYLOAD_FILE}
            #Push lcov
            aws s3 cp --recursive ${CODECOV_OUTPUT}/lcovhtml "s3://${PREFIX}/lcov-unit-coverage/${SUFFIX}/";
            aws s3 cp --recursive ${CODECOV_OUTPUT}/lcovhtml "s3://${PREFIX}/lcov-unit-coverage/latest/";
            echo "lcov available in s3 https://${PREFIX}/lcov-unit-coverage/${SUFFIX}/index.html" >> ${MESSAGE_PAYLOAD_FILE}
      - send_message:
          payload_file: "${MESSAGE_PAYLOAD_FILE}"
          build_url: "${CIRCLE_BUILD_URL}#tests/containers/${CIRCLE_NODE_INDEX}"
          webhook: "${WEBHOOK_COVERAGE_INFO}"

workflows:
  ######################################################################################################################
  # Once a day when a change lands on master coverage
  ######################################################################################################################
  latched-publish-workflow:
    jobs:
      - code_coverage:
          context: libra_ci
          filters:
            branches:
              only:
                - /^test-[\d|.]+$/
                - master

  ######################################################################################################################
  # Will publish release images to dockerhub and aws when commits land on a release/testing branch.                    #
  # Will also push base images to novi aws ecr to prevent dockerhub api limit violations.                              #
  ######################################################################################################################
  release-dockerhub-publish:
    jobs:
      - docker-publish:
          context: docker
          filters:
            branches:
              only:
                - /^test-[\d|.]+$/
                - /^release-[\d|.]+$/
                - master

  ######################################################################################################################
  # Updates documentation when code is committed to master, and checks for breaking changes.
  ######################################################################################################################
  document-publish-workflow:
    jobs:
      - prefetch-crates:
          filters:
            branches:
              only: master
      - check-breaking-change:
          requires:
            - prefetch-crates

  ######################################################################################################################
  # Used by bors to test prs on master's head before committing to master.                                             #
  # The "commit-workflow" must support auto and canary branchs...                                                      #
  # The "commit-workflow", and the  pull-request-workflow should be identical.                                         #
  ######################################################################################################################
  commit-workflow:
    jobs:
      - docker-pre-publish:
          context: docker
          filters:
            branches:
              only: auto
